<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Assessing map uncertainty</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Assessing map uncertainty</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(Racmacs)</span></code></pre></div>
<div id="assessing-uncertainty-in-an-antigenic-map" class="section level1">
<h1>Assessing uncertainty in an antigenic map</h1>
<p>Once you have generated an antigenic map there are several methods to
try and assess uncertainty, and different potential sources of
uncertainty to consider. The different functions in Racmacs relate to
these different sources as follows:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Uncertainty</th>
<th align="left">Method</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Geometric uncertainty</td>
<td align="left"><code>triangulationBlobs()</code></td>
</tr>
<tr class="even">
<td align="left">Sample variation</td>
<td align="left"><code>bootstrapBlobs()</code> with
<code>method = “resample”</code> or
<code>method = “bayesian”</code></td>
</tr>
<tr class="odd">
<td align="left">Measurement noise and bias</td>
<td align="left"><code>bootstrapBlobs()</code> with
<code>method = “noisy”</code></td>
</tr>
</tbody>
</table>
<p>This article discusses these sources of error and the corresponding
functions to help you decide how best to apply them to your data.</p>
<div id="a-note-on-confidence-vs-actual-goodness-of-fit" class="section level3">
<h3>A note on confidence vs actual goodness of fit</h3>
<p>With all these methods it is important to consider that we are
addressing the degree of uncertainty present in the solution to the map,
given the map as a model for your data. This is an important distinction
since we are not addressing the question of how well a particular map
represents the data, which is covered in other articles. This is
analogous to fitting e.g. a straight regression line through some data,
the line could be a bad fit to the true patterns in the data, yet you
could be very confident that if you really insist on fitting a straight
line, you have the best parameters for the slope and intercept. It is
like that with these methods, here we are addressing the confidence we
have in the parameters of best in our model, not whether the best fit is
a good representation.</p>
</div>
<div id="geometric-uncertainty-and-triangulation-blobs" class="section level2">
<h2>Geometric uncertainty and triangulation blobs</h2>
<p>A first source of uncertainty to consider is how constrained or not
the point positions are in your map given the information you have. In
an extreme case, if you had only a single measurement for an antigen
against a single serum, you could calculate an expected distance that
the antigen should be from that serum, but you would not have sufficient
information to triangulate its position in e.g. 2 dimensional space. In
reality of course, the situation is rarely as clear cut as that and,
indeed in that particular scenario, Racmacs would exclude that point
with a warning that there were an insufficient number of titrations to
coordinate it. More commonly, titer information is such that an optimal
solution place a point at a particular place on the map, but there is a
broader region where the solution is almost as good. This is what the
<code>triangulationBlobs()</code> function tries to represent. In
particular it takes each point then performs a grid search to see how
stress varies for that point in different regions of the space, before
drawing a blob to demarcate the region of space where the total stress
increase is below a certain threshold. As you can imagine the stress
threshold you choose is an important determinant of how big the bob
regions will be. A generally sensible default of 1 unit increase of
stress is the default but there is no a prior reason for this value and
it is the relative size of the blobs that gives the most useful
information of how constrained certain point positions are relative to
others.</p>
<p>It is tempting to think of these triangulationBlobs as somehow
representing confidence or credibility regions, but this is not the
case, for example a point position may be well coordinated geometrically
but heavily dependent on a particular titer or set of tiers that may in
themselves not be reliable. In our own work these triangulation blobs
mostly help inform whether there is enough information to start with to
really determine positions of strains well in a given number of
dimensions, or are e.g. more titrations against different types of sera
required.</p>
</div>
<div id="bootstrapping-methods" class="section level2">
<h2>Bootstrapping methods</h2>
<div id="bootstrapping-to-assess-sample-uncertainty" class="section level3">
<h3>Bootstrapping to assess sample uncertainty</h3>
<p>A key question in statistics is how well parameters fitted against a
population sample are likely to represent the parameters of the
population as a whole. The standard error of the mean is a classic
estimator of this. There is the same issue with antigenic maps, for
example how consistent would the map solution be if we imagine a
different subset of similar antigens and sera had been titrated? Since
there is no clear analytical solution to this, we apply the approach of
bootstrapping to estimate these types of uncertainty.</p>
<p>There are several variant bootstrapping methods and the
<code>bootstrapMap()</code> function performs these types of analyses
with the option to choose between three different approaches,
<code>“resample”</code> and <code>“bayesian”</code>, discussed in this
section, and <code>“noisy”</code>, discussed further below.</p>
<p>Of the methods above, <code>method = “resample”</code> is the most
vanilla flavour of bootstrapping, taking a standard approach of
resampling the original data, with replacement so that in the resulting
dataset some entries will be represented multiple times and some not at
all, thereby introducing variation into the original sample.
<code>method = “bayesian”</code> is conceptually similar to “resample”
but rather than actually resampling the data it achieves a similar
effect through re-weighting the data according to a ?? distribution with
each repeat. A key difference is that no point is ever actually totally
excluded in the bayesian method and therefore if your map is
particularly dependent on a certain antigen or antigens for overall
geometric coordination, the bayesian method will tend to yield more
consistent results. On the flip side, the resample method can help
express uncertainty due to precisely this issue of reliance on a small
number of particular strains or sera for overall map coordination and is
there the more conservative of the two approaches.</p>
<p>The primary option in these bootstrapping approaches is the number of
bootstrap resamples to perform, since each of these will be one
realisation of a different map under an alternative simulated sample. To
get an accurate assessment of how positions seem to vary with each run,
at least 1000 is recommended, with more helping better to observe
positional uncertainty and variation but becoming more expensive both
with regards to computing time and also memory to store the results.</p>
<p>Further options include whether to apply the resampling to both
antigens and sera (the default) or just one or the other, for example
antigens = FALSE may help explore how sensitive is your particular
constellation of antigens to different samples of sera. You can also
decide whether to reoptimize the map from scratch with each bootstrap
repeat, the default, or simply relax the map from its current
configuration. The latter will be considerably faster but isn’t
recommended since each repeat will have more of a tendency to become
trapped in a local optima that’s similar to the starting configuration
and therefore under-represent the true map uncertainty. Relatedly, when
reoptimizing from scratch, you can also specify the number of
optimizations runs for each sample. For maps that are easy to optimize
only a small number of runs would be required, but for larger more
complex maps this should ideally be around the number of optimization
runs it took to consistently find the lowest stress solution for your
original map in the first place. Since the reoptimization from scratch
procedure can be so computationally expensive (1000 bootstrap repeats
with 200 reoptimizations from scratch each = 200000 optimization runs!)
the temptation is to skimp on these numbers, but if too few runs are
allowed to give a chance of finding optimal solutions, uncertainty in
the end sample may be overrepresented.</p>
</div>
<div id="bootstrapping-to-assess-measurement-error-uncertainty" class="section level3">
<h3>Bootstrapping to assess measurement error uncertainty</h3>
<p>Generally, the resampling based bootstrap methods described above
work best where there are a sufficient number of similar antigens and
sera such that the sample is meaningfully representative of the
distribution of variation in a theoretical wider population, for example
multiple antigens and sera from each antigenic cluster in the 2004 H3
map. In reality this is not always the case but if we have some idea of
the expected size of the measurement error associated with the data we
can get some idea of how this may be affecting uncertainty in our
resulting map by applying imaginary additional noise to our dataset and
seeing how much map positions vary as a result. This is not a perfect
approach since each sample with then have measurement noise applied
twice, once originally and once artificially, but since in a simple
system the artificial noise will cancel out measurement noise on average
as much as it adds to it, it still works as a reasonable estimator of
measurement noise based uncertainty.</p>
<p>In all datasets we have so far studied we find there are two
important categories of noise to consider, the first is the expected
noise due to general assay variation that tends to lead to unbiased
variation in repeat data. We call this “titer” noise and is generally
what most people think about when it comes to experimental noise. The
second and far more pernicious noise is noise in antigen measurements
that leads to a consistent bias in any given set of repeats, in this
category for influenza are things like slight fluctuation in starting
virus concentration after titrating to 4HAUs, different RBCs being used
etc. Relatedly there is also bias that may be consistently present for
an antigen even between repeats due to inherent but non-antigenically
related differences, often referred to as high or low avidity strains,
or strains with a tendency to be more easily neutralized etc. Since both
these types of error have the same result of biasing all titers against
an antigen to be consistently higher or lower, we call this “antigen
noise”.</p>
<p>While antigenic cartography typically does a great job of averaging
out titer noise, antigen noise is trickier since there is no a priori
way to know whether an antigen has low titers because of additional
antigenic escape or falsely biased low reactivity in the assay. In the
real world we often have clues, for example biased varation between
repeats done at different times or low titers against homologous sera,
but such information is not built into the cartography software. We can
however simulate the effects of such noise in creating uncertainty in
the map and that is the idea of the <code>method = “noisy”</code>
bootstrap approach. As you can perhaps imagine, in addition to options
shared with the methods above, key parameters are how much titer and
antigen noise to simulate. Based on our influenza work both the titer
noise and antigen noise is set at a default of standard deviation = 0.7,
but depending on your data these may be wild over- or under-estimates.
By default both titer and antigen noise are applied, with tirer noise
randomly determined and applied separately to each cell in the titer
table for each repeat and antigen noise determined and applied to each
row. In practise, especially given the tricky nature of estimating
antigen reactivity bias, it can be useful to look at the effect of titer
noise on it’s own first, by setting the
<code>antigen_noise_sd = 0</code>, then see the effect in combination
with some possible per-antigen noise.</p>
</div>
<div id="viewing-bootstrap-results" class="section level3">
<h3>Viewing bootstrap results</h3>
<p>Once you have run your desired bootstrap method you will want to
visualise the results. One way is to open a map that you have run
bootstrapping on in the Racmacs viewer. If bootstrapping data is present
then when you select a point, a cloud of points appears representing the
relative position of that point in each of the bootstrap runs done,
allowing you to visualise variation explicitly. A second approach is to
use the <code>bootstrapBlobs()</code> function to calculate an area that
encompasses a certain proportion of the positional variation across the
repeats. In this case, the conf.level argument sets the proportion of
variation to capture, with the default set at 0.68, approximately
equivalent to one standard deviation of the normal distribution.</p>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
